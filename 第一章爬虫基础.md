# HTTP基本原理

URI (Universal Resource Name): 指定名字

URL (Uniform Resource Locator): 指定了访问协议Http，访问路径和资源名称

URI+URL = URI(Uniform Resource Identifier)

![image](https://user-images.githubusercontent.com/77183284/123872381-a1a06880-d8fa-11eb-93e4-6dc7926f371a.png)

# 超文本(Hypertext)

HTML(Hyper Text Transfer Protocol) 由万维网协会和Internet工作小组IETF合作制定

HTTPS(Hyper Text Transfer Protocol over Secure Socket Layer) 以安全为目标的HTTP通道

SSL的作用

1. 建立安全通道保护传输数据

2. 确认网站真实性，可以点击地址栏的锁头来看网站认证后的信息，也可以根据CA机构颁发的安全签章查询

注：部分网站不受CA机构信任（如：中国铁道部），需要设置忽略证书的选项，否则会SSL链接错误。

HPPT请求反馈: Name(请求的名字), Status(响应码), Type(文档类型), Initiator(请求源), Size(从服务器下载的文件和请求的资源大小), Time(响应时间), Waterfall(可视化瀑布流)

### 请求

请求方法： GET&POST

GET：参数在URL里面，且最多1024个字节。

POST：表单形式传输，无数据限制（密码等隐私最好用POST）

>![image](https://user-images.githubusercontent.com/77183284/123874428-c9450000-d8fd-11eb-93d8-f71324f1c933.png)


* 请求头

|名称|内容|
|:-:|:-:|
|Accept|请求报头域，客户端接收信息类型|
|Accept-Language|客户端语言类型|
|Accept-Encoding|客户端可接受的内容编码|
|Host|请求资源的主机IP和端口号|
|Cookie|辨别、跟踪用户而存储在用户本地的数据，用于维持当前访问会话。|
|Referer|用于标识请求从那个页面发过来的|
|User-Agent|识别客户使用的操作系统、版本、浏览器以及其版本等信息|
|Content-Type|互联网媒体类型（text/html表示HTML，image/gif代表GIF图片，application/json代表JSON类型）|

* 请求体

>![image](https://user-images.githubusercontent.com/77183284/123875857-0611f680-d900-11eb-903e-d4118017e1e0.png)

### 响应

![image](https://user-images.githubusercontent.com/77183284/123876082-6012bc00-d900-11eb-964b-0faaa3f4dd6f.png)
![image](https://user-images.githubusercontent.com/77183284/123876137-77ea4000-d900-11eb-84b7-7ad0aa955d42.png)

* 响应头

|名称|内容|
|:-:|:-:|
|Date|响应时间|
|Content-Encoding|响应内容的编码|
|Server|服务器信息|
|Content-Type|返回数据类型|
|Set-Cookie|将此内容放到Cookies中，下次请求携带Cookies|
|Expires|响应的过期时间，可以使代理服务器活浏览器将加载内容放到缓存，加快响应速度|

* 响应体

响应的数据都在响应体中！！：）

# 网页基础

对于HTML，所有元素都是节点，他们的关系为parent，sibling，child

### 选择器

CSS：# 选择id，.wrapper 选择class，<h2></h2> 标签名筛选 （用空格表示嵌套关系：#container .wrapper p，id为container中的wrapper中的p）

![image](https://user-images.githubusercontent.com/77183284/123877877-a4538b80-d903-11eb-8c93-433ee669e548.png)
![image](https://user-images.githubusercontent.com/77183284/123877893-addcf380-d903-11eb-9bd6-4777e0cbd3a6.png)

# 爬虫的基本原理

将获取网页并保存的过程自动化

1. 获取网页：向网站服务器发送请求，获得网页源代码，并解析

2. 提取信息：提取我们想要的数据，可采用方法：正则表达式（万能但易错），根据网页节点、CSS选择器或XPath提取

3. 保存数据：txt，json，或者数据库MySQL和MongoDB，或者远端服务器（借助FTP）

# 代理的基本原理 Proxy server

防止爬虫频率过高被反爬虫的操作。

将请求发给代理服务器，代理服务器发送给Web服务器，从而实现IP伪装。

### 代理的作用

1. 突破访问限制

2. 访问内部资源

3. 提高访问速度

4. 隐藏真实IP

### 代理分类

* 根据协议： 
FTP代理服务器（端口：21、2121）、HTTP代理服务器（端口：8080、3128）、SSL/TLS代理（端口：443）、RTSP代理（端口：554）、Telnet代理（端口：23）、POP3/SMTP代理（端口：110/25）、SOCKS代理（端口：1080）

* 根据匿名程度：

高匿名程度：将数据包原封不动地转发

普通匿名程度：在数据包上做一定地改动。可能会被发现，有几率追查到真实IP

透明代理：改动数据包，并告诉服务器客户端真实IP。提高浏览速度以及安全性（过滤内容），常见于内网的硬件防火墙。

间谍代理：组织或个人创建用于记录用户传输的数据，并进行研究或监控的代理服务器。

### 常见代理设置

使用网上的免费代理：最好使用高匿名代理，另外可用的代理不多，需要使用前筛选一下。
使用付费代理服务：付费代理，质量好。
ADSL拨号：拨一次号换一次IP，稳定性高。
